{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61790566",
   "metadata": {},
   "source": [
    "# SNN vs ANN Comparison - Variant C Demo\n",
    "\n",
    "This notebook demonstrates the implementation and training of a Spiking Neural Network (SNN) using PyTorch and snnTorch, comparing it with conventional ANNs.\n",
    "\n",
    "## Setup Instructions\n",
    "1. First, we'll install the required packages\n",
    "2. Then we'll implement and train an SNN model\n",
    "3. Finally, we'll evaluate and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b4fee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (0.24.0)\n",
      "Requirement already satisfied: snntorch in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (0.9.4)\n",
      "Requirement already satisfied: matplotlib in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: filelock in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shahdhruv/Desktop/Research/SNN/.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision snntorch matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "209d3297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42639c0",
   "metadata": {},
   "source": [
    "## SNN Model Definition\n",
    "\n",
    "We'll implement a spiking CNN using Leaky Integrate-and-Fire (LIF) neurons from snnTorch. The model consists of:\n",
    "1. Two convolutional layers with LIF neurons\n",
    "2. MaxPooling layers for dimensionality reduction\n",
    "3. A fully connected output layer with LIF neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61c20a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNNCNN(\n",
      "  (conv1): Conv2d(1, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lif1): Leaky()\n",
      "  (conv2): Conv2d(12, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lif2): Leaky()\n",
      "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (lif3): Leaky()\n",
      ")\n",
      "\n",
      "Total trainable parameters: 29,978\n"
     ]
    }
   ],
   "source": [
    "class SNNCNN(nn.Module):\n",
    "    def __init__(self, num_inputs=784, num_hidden=256, num_outputs=10, beta=0.95):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize with kaiming normal for better gradient flow\n",
    "        self.conv1 = nn.Conv2d(1, 12, 5)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid())\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(12, 64, 5)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid())\n",
    "        \n",
    "        # Calculate size after convolutions and pooling\n",
    "        self.num_flat_features = 64 * 4 * 4\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.num_flat_features, num_outputs)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid())\n",
    "        \n",
    "        # Total number of neurons for AFR calculation\n",
    "        self.num_neurons = (\n",
    "            12 * 24 * 24 +  # After conv1\n",
    "            64 * 8 * 8 +    # After conv2\n",
    "            num_outputs     # Output layer\n",
    "        )\n",
    "        \n",
    "        # Initialize membrane potentials\n",
    "        self.reset_states()\n",
    "    \n",
    "    def reset_states(self):\n",
    "        \"\"\"Reset all membrane potentials.\"\"\"\n",
    "        self.mem1 = None\n",
    "        self.mem2 = None\n",
    "        self.mem3 = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        \n",
    "        # Initialize hidden states if None\n",
    "        if self.mem1 is None:\n",
    "            self.mem1 = self.lif1.init_leaky()\n",
    "        if self.mem2 is None:\n",
    "            self.mem2 = self.lif2.init_leaky()\n",
    "        if self.mem3 is None:\n",
    "            self.mem3 = self.lif3.init_leaky()\n",
    "        \n",
    "        # Record spikes for AFR calculation\n",
    "        spk1_rec = []\n",
    "        spk2_rec = []\n",
    "        out_rec = []\n",
    "        \n",
    "        for step in range(x.size(0)):\n",
    "            cur1 = self.bn1(F.max_pool2d(self.conv1(x[step]), 2))\n",
    "            spk1, self.mem1 = self.lif1(cur1, self.mem1)\n",
    "            \n",
    "            cur2 = self.bn2(F.max_pool2d(self.conv2(spk1), 2))\n",
    "            spk2, self.mem2 = self.lif2(cur2, self.mem2)\n",
    "            \n",
    "            cur3 = self.fc1(spk2.flatten(1))\n",
    "            spk3, self.mem3 = self.lif3(cur3, self.mem3)\n",
    "            \n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "            out_rec.append(spk3)\n",
    "        \n",
    "        return torch.stack(out_rec, dim=0)\n",
    "    \n",
    "    def compute_afr(self, spk_rec):\n",
    "        \"\"\"Compute Average Firing Rate as percentage of total possible spikes.\"\"\"\n",
    "        total_spikes = torch.sum(spk_rec)\n",
    "        total_neurons = self.num_neurons\n",
    "        total_timesteps = spk_rec.size(0)\n",
    "        total_samples = spk_rec.size(1)\n",
    "        \n",
    "        max_possible_spikes = total_neurons * total_timesteps * total_samples\n",
    "        afr = 100.0 * total_spikes.float() / max_possible_spikes\n",
    "        return afr.item()\n",
    "\n",
    "# Create model instance\n",
    "model = SNNCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# Print parameter count\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e13ea",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "For this demo, we'll generate synthetic image-like data similar to MNIST format:\n",
    "- Input shape: (batch_size, 1, 28, 28)\n",
    "- 10 output classes\n",
    "- Simple patterns for class determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ff86271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1000\n",
      "Test samples: 200\n",
      "Input shape: torch.Size([1, 28, 28])\n",
      "Number of classes: 10\n",
      "Data range: [-4.57, 4.22]\n"
     ]
    }
   ],
   "source": [
    "def generate_synthetic_data(num_samples=1000, input_size=28, num_classes=10):\n",
    "    \"\"\"Generate synthetic image-like data with distinct patterns per class.\"\"\"\n",
    "    # Create base patterns for each class\n",
    "    patterns = torch.randn(num_classes, 1, input_size, input_size)\n",
    "    patterns = F.avg_pool2d(patterns, kernel_size=4, stride=2, padding=1)\n",
    "    patterns = F.interpolate(patterns, size=(input_size, input_size), mode='bilinear')\n",
    "    \n",
    "    # Initialize storage\n",
    "    images = torch.zeros(num_samples, 1, input_size, input_size)\n",
    "    labels = torch.zeros(num_samples, dtype=torch.long)\n",
    "    \n",
    "    # Generate samples\n",
    "    for i in range(num_samples):\n",
    "        label = i % num_classes\n",
    "        # Get base pattern and add noise\n",
    "        base = patterns[label].clone()\n",
    "        noise = torch.randn_like(base) * 0.1\n",
    "        images[i] = base + noise\n",
    "        labels[i] = label\n",
    "    \n",
    "    # Normalize to [-1, 1]\n",
    "    images = (images - images.mean()) / (images.std() + 1e-5)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Generate training and test data\n",
    "num_samples = 1000\n",
    "num_steps = 25\n",
    "batch_size = 32\n",
    "\n",
    "# Create train/test sets\n",
    "X_train, y_train = generate_synthetic_data(num_samples)\n",
    "X_test, y_test = generate_synthetic_data(num_samples // 5)\n",
    "\n",
    "# Create data loaders with pin_memory for faster GPU transfer\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train, y_train),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(X_test, y_test),\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Input shape: {X_train[0].shape}\")\n",
    "print(f\"Number of classes: {len(torch.unique(y_train))}\")\n",
    "print(f\"Data range: [{X_train.min():.2f}, {X_train.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8e999",
   "metadata": {},
   "source": [
    "## Training Functions\n",
    "\n",
    "We'll implement functions for:\n",
    "1. Training one epoch\n",
    "2. Validation with AFR computation\n",
    "3. Training loop with loss and accuracy tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15256c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training setup complete\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, optimizer, device, num_steps):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for data, targets in train_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Reset model states before each batch\n",
    "        model.reset_states()\n",
    "        \n",
    "        # Expand input for time steps\n",
    "        data = data.unsqueeze(0).repeat(num_steps, 1, 1, 1, 1)\n",
    "        spk_rec = model(data)\n",
    "        \n",
    "        # Loss and accuracy (average over time steps)\n",
    "        output = spk_rec.mean(0)  # Average over time steps\n",
    "        loss = F.cross_entropy(output, targets)\n",
    "        acc = (output.argmax(1) == targets).float().mean() * 100\n",
    "        \n",
    "        # Gradient computation and weight updates\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)  # Added retain_graph=True\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_size = len(targets)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_acc += acc.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / total_samples,\n",
    "        'accuracy': total_acc / total_samples\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c38bb6",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Now we'll train the model for multiple epochs, tracking:\n",
    "1. Training loss and accuracy\n",
    "2. Validation accuracy\n",
    "3. Average Firing Rate (AFR)\n",
    "4. Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f50e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     56\u001b[39m epoch_start_time = time.time()\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m train_stats = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m     62\u001b[39m val_stats = validate(model, test_loader, device, num_steps)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, optimizer, device, num_steps)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Gradient computation and weight updates\u001b[39;00m\n\u001b[32m     22\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m optimizer.step()\n\u001b[32m     26\u001b[39m batch_size = \u001b[38;5;28mlen\u001b[39m(targets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/SNN/.venv/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/SNN/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/SNN/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10\n",
    "history = {\n",
    "    'loss': [], 'accuracy': [], \n",
    "    'val_accuracy': [], 'val_afr': [],\n",
    "    'time_per_epoch': []\n",
    "}\n",
    "\n",
    "def plot_training_progress():\n",
    "    \"\"\"Plot real-time training progress.\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax1.plot(history['loss'], 'b-')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    \n",
    "    # Plot accuracies\n",
    "    epochs = range(1, len(history['accuracy']) + 1)\n",
    "    ax2.plot(epochs, history['accuracy'], 'b-', label='Train')\n",
    "    ax2.plot(epochs, history['val_accuracy'], 'r-', label='Validation')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Plot AFR\n",
    "    ax3.plot(epochs, history['val_afr'], 'g-')\n",
    "    ax3.set_title('Average Firing Rate')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('AFR (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print latest metrics\n",
    "    print(f\"\\nLatest metrics (Epoch {len(epochs)}):\")\n",
    "    print(f\"  Train Loss: {history['loss'][-1]:.4f}\")\n",
    "    print(f\"  Train Accuracy: {history['accuracy'][-1]:.2f}%\")\n",
    "    print(f\"  Val Accuracy: {history['val_accuracy'][-1]:.2f}%\")\n",
    "    print(f\"  Average Firing Rate: {history['val_afr'][-1]:.2f}%\")\n",
    "    print(f\"  Time per epoch: {history['time_per_epoch'][-1]:.2f}s\")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Make sure model is in training mode\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Training\n",
    "    train_stats = train(model, train_loader, optimizer, device, num_steps)\n",
    "    \n",
    "    # Validation\n",
    "    val_stats = validate(model, test_loader, device, num_steps)\n",
    "    \n",
    "    # Record history\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    history['loss'].append(train_stats['loss'])\n",
    "    history['accuracy'].append(train_stats['accuracy'])\n",
    "    history['val_accuracy'].append(val_stats['accuracy'])\n",
    "    history['val_afr'].append(val_stats['afr'])\n",
    "    history['time_per_epoch'].append(epoch_time)\n",
    "    \n",
    "    # Plot progress\n",
    "    if (epoch + 1) % 1 == 0:  # Update every epoch\n",
    "        plot_training_progress()\n",
    "\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "print(f\"Average time per epoch: {np.mean(history['time_per_epoch']):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9d3dd",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "Let's plot the training results:\n",
    "1. Training loss over epochs\n",
    "2. Training and validation accuracy\n",
    "3. Average Firing Rate progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036a9f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/SNN/.venv/lib/python3.13/site-packages/matplotlib/style/core.py:129\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     style = \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/SNN/.venv/lib/python3.13/site-packages/matplotlib/__init__.py:906\u001b[39m, in \u001b[36m_rc_params_in_file\u001b[39m\u001b[34m(fname, transform, fail_on_error)\u001b[39m\n\u001b[32m    905\u001b[39m rc_temp = {}\n\u001b[32m--> \u001b[39m\u001b[32m906\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:141\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/SNN/.venv/lib/python3.13/site-packages/matplotlib/__init__.py:883\u001b[39m, in \u001b[36m_open_file_or_url\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m    882\u001b[39m fname = os.path.expanduser(fname)\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'seaborn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set style for better visualization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseaborn\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create figure for multiple plots\u001b[39;00m\n\u001b[32m      5\u001b[39m fig = plt.figure(figsize=(\u001b[32m20\u001b[39m, \u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/SNN/.venv/lib/python3.13/site-packages/matplotlib/style/core.py:131\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    129\u001b[39m         style = _rc_params_in_file(style)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    132\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m is not a valid package style, path of style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile, URL of style file, or library style name (library \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstyles are listed in `style.available`)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    135\u001b[39m filtered = {}\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: 'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "# Create figure for multiple plots\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "# 1. Training curves\n",
    "ax1 = plt.subplot(231)\n",
    "ax1.plot(history['loss'], 'b-', label='Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True)\n",
    "\n",
    "# 2. Accuracy curves\n",
    "ax2 = plt.subplot(232)\n",
    "epochs = range(1, len(history['accuracy']) + 1)\n",
    "ax2.plot(epochs, history['accuracy'], 'b-', label='Train')\n",
    "ax2.plot(epochs, history['val_accuracy'], 'r-', label='Validation')\n",
    "ax2.set_title('Model Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# 3. AFR progression\n",
    "ax3 = plt.subplot(233)\n",
    "ax3.plot(epochs, history['val_afr'], 'g-')\n",
    "ax3.set_title('Average Firing Rate')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('AFR (%)')\n",
    "ax3.grid(True)\n",
    "\n",
    "# 4. Time per epoch\n",
    "ax4 = plt.subplot(234)\n",
    "ax4.plot(epochs, history['time_per_epoch'], 'm-')\n",
    "ax4.set_title('Time per Epoch')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Seconds')\n",
    "ax4.grid(True)\n",
    "\n",
    "# 5. Example predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get sample batch\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Reset model states\n",
    "    model.reset_states()\n",
    "    \n",
    "    # Forward pass\n",
    "    spk_rec = model(images.unsqueeze(0).repeat(num_steps, 1, 1, 1, 1))\n",
    "    predictions = spk_rec.mean(0).argmax(1)\n",
    "    \n",
    "    # Plot first 9 examples\n",
    "    for idx in range(min(9, len(images))):\n",
    "        plt.subplot(2, 3, 5 + (idx > 4))\n",
    "        plt.imshow(images[idx].cpu().squeeze(), cmap='gray')\n",
    "        plt.title(f'True: {labels[idx].item()}\\nPred: {predictions[idx].item()}')\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "if len(history['val_accuracy']) > 0:  # Check if we have any history\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Validation Accuracy: {history['val_accuracy'][-1]:.2f}%\")\n",
    "    print(f\"Average Firing Rate: {history['val_afr'][-1]:.2f}%\")\n",
    "    print(f\"Final Loss: {history['loss'][-1]:.4f}\")\n",
    "    print(f\"Training Time: {total_time:.2f} seconds\")\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "\n",
    "# Model summary\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10650af",
   "metadata": {},
   "source": [
    "## Save Model and Results\n",
    "\n",
    "Finally, let's save the trained model and results for future use. This includes:\n",
    "1. Model state dictionary\n",
    "2. Training history\n",
    "3. Final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7eb6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Save final metrics to text file\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mmodels/results.txt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     f.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m     f.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal Average Firing Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory[\u001b[33m'\u001b[39m\u001b[33mval_afr\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m     f.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Save model checkpoint\n",
    "if len(history['val_accuracy']) > 0:  # Only save if we have training history\n",
    "    checkpoint = {\n",
    "        'epoch': num_epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'history': history,\n",
    "    }\n",
    "\n",
    "    import os\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    torch.save(checkpoint, 'models/snn_model.pth')\n",
    "\n",
    "    # Save final metrics to text file\n",
    "    with open('models/results.txt', 'w') as f:\n",
    "        f.write(f\"Final Validation Accuracy: {history['val_accuracy'][-1]:.2f}%\\n\")\n",
    "        f.write(f\"Final Average Firing Rate: {history['val_afr'][-1]:.2f}%\\n\")\n",
    "        f.write(f\"Training Time: {total_time:.2f} seconds\\n\")\n",
    "\n",
    "    print(\"Model and results saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
